{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "import parfit.parfit as pf\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, as an illustration of a real-world problem, you are asked to predict the evolution of hospital patients' states and needs during their stay in the Intensive Care Unit (ICU). For each patient, you are provided with the monitoring information collected during the first 12h of their stay. From the data, you first need to extract meaningful features describing this 12h stay. Then, for each sub-task, you should select an appropriate model to train on your pre-processed data. You will face the typical challenges of working with real medical data: missing features and imbalanced classification, predicting rarely-occuring events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227940"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data set\n",
    "df_train_features = pd.read_csv('train_features.csv')\n",
    "df_train_labels = pd.read_csv('train_labels.csv')\n",
    "df_test_features = pd.read_csv('test_features.csv')\n",
    "\n",
    "# pre-process the training data (impute the missing data)\n",
    "training_features = pd.DataFrame(df_train_features.groupby(['pid']).mean())\n",
    "imputed_training_features = df_train_features.reset_index().drop(columns=['pid', 'Time']).fillna(training_features.mean())\n",
    "\n",
    "# pre-process the test data (impute the missing data)\n",
    "test_features = pd.DataFrame(df_test_features.groupby(['pid']).mean())\n",
    "imputed_test_features = test_features.reset_index().drop(columns=['pid', 'Time']).fillna(test_features.mean())\n",
    "\n",
    "# format the training labels\n",
    "training_labels = df_train_labels.drop(columns=['pid'])\n",
    "\n",
    "training_features.head(1000)\n",
    "imputed_training_features.head(1000)\n",
    "len(imputed_training_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sub-Task 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are interested in anticipating the future needs of the patient. You have to predict whether a certain medical test is ordered by a clinician in the remaining stay. This sub-task is a binary classification : 0 means that there will be no further tests of this kind ordered whereas 1 means that at least one is ordered in the remaining stay.\n",
    "\n",
    "The corresponding columns containing the binary ground truth in train_labels.csv are: LABEL_BaseExcess, LABEL_Fibrinogen, LABEL_AST, LABEL_Alkalinephos, LABEL_Bilirubin_total, LABEL_Lactate, LABEL_TroponinI, LABEL_SaO2, LABEL_Bilirubin_direct, LABEL_EtCO2.\n",
    "\n",
    "Because there is an imbalance between labels in these sub-tasks we evaluate the performance of a model with the Area Under the Receiver Operating Characteristic Curve, which is a threshold-based metric. To achieve good performance, it is important to produce (probabilistic) real-valued predictions in the interval [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# labels needed for sub-task 1\n",
    "labels_1 = training_labels[['LABEL_BaseExcess', 'LABEL_Fibrinogen', 'LABEL_AST', 'LABEL_Alkalinephos', 'LABEL_Bilirubin_total', 'LABEL_Lactate', 'LABEL_TroponinI', 'LABEL_SaO2', 'LABEL_Bilirubin_direct', 'LABEL_EtCO2']]\n",
    "\n",
    "# split training data into training and validation set\n",
    "X_train_1, X_val_1, y_train_1, y_val_1 = train_test_split(imputed_training_features, labels_1, test_size= 0.2, random_state=None, shuffle=False)\n",
    "\n",
    "clf = make_pipeline(StandardScaler(), SVC(kernel='rbf', max_iter=1000, tol=1e-3))\n",
    "\n",
    "for col in labels_1:\n",
    "    clf.fit(X_train_1, y_train_1[col])\n",
    "    y_pred_1 = clf.predict(X_val_1)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_val_1[col], y_pred_1)\n",
    "    plt.plot(fpr, tpr)\n",
    "    print(roc_auc_score(y_val_1[col], y_pred_1))\n",
    "    \n",
    "\n",
    "\n",
    "# avg_ROC = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels needed for sub-task 1\n",
    "labels_1 = training_labels[['LABEL_BaseExcess', 'LABEL_Fibrinogen', 'LABEL_AST', 'LABEL_Alkalinephos', 'LABEL_Bilirubin_total', 'LABEL_Lactate', 'LABEL_TroponinI', 'LABEL_SaO2', 'LABEL_Bilirubin_direct', 'LABEL_EtCO2']]\n",
    "\n",
    "# split training data into training and validation set\n",
    "X_train_1, X_val_1, y_train_1, y_val_1 = train_test_split(imputed_training_features, labels_1, test_size= 0.2, random_state=42)\n",
    "\n",
    "# clf = make_pipeline(StandardScaler(), SGDClassifier(loss='squared_epsilon_insensitive', penalty='elasticnet', fit_intercept=False, max_iter=1000, tol=1e-3, shuffle=False))\n",
    "# clf = RandomForestClassifier()\n",
    "clf_1 = SGDClassifier(loss='log', max_iter=1000, tol=1e-3)\n",
    "\n",
    "for col in labels_1:\n",
    "    clf_1.fit(X_train_1, y_train_1[col])\n",
    "    y_pred_1 = clf_1.predict_proba(X_val_1)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_val_1[col], y_pred_1)\n",
    "    plt.plot(fpr, tpr)\n",
    "    print(roc_auc_score(y_val_1[col], y_pred_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sub-Task 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this sub-task, we are interested in anticipating future life-threatening events. You have to predict whether a patient is likely to have a sepsis event in the remaining stay. This task is also a binary classification : 0 means that no sepsis will occur, 1 otherwise.\n",
    "\n",
    "The corresponding column containing the binary ground-truth in train_labels.csv is LABEL_Sepsis.\n",
    "\n",
    "This task is also imbalanced, thus weâ€™ll also evaluate performance using Area Under the Receiver Operating Characteristic Curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels needed for sub-task 2\n",
    "labels_2 = training_labels[['LABEL_Sepsis']]\n",
    "\n",
    "# split training data into training and validation set\n",
    "X_train_2, X_val_2, y_train_2, y_val_2 = train_test_split(imputed_training_features, labels_2, test_size= 0.2, random_state=42)\n",
    "\n",
    "clf_2 = SGDClassifier(loss='log', max_iter=1000, tol=1e-3)\n",
    "\n",
    "clf_2.fit(X_train_2, y_train_2)\n",
    "y_pred_2 = clf_2.predict_proba(X_val_2)    \n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_val_2, y_pred_2)\n",
    "plt.plot(fpr, tpr)\n",
    "print(roc_auc_score(y_val_2, y_pred_2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sub-Task 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this type of sub-task, we are interested in predicting a more general evolution of the patient state. To this effect, here we aim at predicting the mean value of a vital sign in the remaining stay. This is a regression task.\n",
    "\n",
    "The corresponding columns containing the real-valued ground truth in train_labels.csv are: LABEL_RRate, LABEL_ABPm, LABEL_SpO2, LABEL_Heartrate.\n",
    "\n",
    "To evaluate the performance of a given model on this sub-task we use R2 Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels needed for sub-task 3\n",
    "labels_3 = training_labels[['LABEL_RRate', 'LABEL_ABPm', 'LABEL_SpO2', 'LABEL_Heartrate']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_st1 = imputed_test_features\n",
    "\n",
    "# suppose df is a pandas dataframe containing the result\n",
    "#df.to_csv('prediction.zip', index=False, float_format='%.3f', compression='zip')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7df4d15e59cac213afef75c805c6c35b948ade230879836dc77c436b6318e246"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('intro-ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
