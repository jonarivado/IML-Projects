{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid, GridSearchCV, StratifiedKFold, RepeatedKFold\n",
    "from sklearn.linear_model import SGDClassifier, LinearRegression, LogisticRegression, RidgeCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data set\n",
    "df_train_features = pd.read_csv('train_features.csv')\n",
    "df_train_labels = pd.read_csv('train_labels.csv')\n",
    "df_test_features = pd.read_csv('test_features.csv')\n",
    "\n",
    "# add labels with matching pid to features\n",
    "labels_copied = pd.DataFrame()\n",
    "labels_copied = df_train_labels.loc[df_train_labels.index.repeat(12)]\n",
    "labels_copied = labels_copied.drop(columns=['pid'])\n",
    "labels = df_train_labels.drop(columns=['pid'])\n",
    "\n",
    "LABELS1 = ['LABEL_BaseExcess', 'LABEL_Fibrinogen', 'LABEL_AST', 'LABEL_Alkalinephos', 'LABEL_Bilirubin_total',\n",
    "         'LABEL_Lactate', 'LABEL_TroponinI', 'LABEL_SaO2',\n",
    "         'LABEL_Bilirubin_direct', 'LABEL_EtCO2']\n",
    "LABELS2 = ['LABEL_Sepsis']\n",
    "LABELS3 = ['LABEL_RRate', 'LABEL_ABPm', 'LABEL_SpO2', 'LABEL_Heartrate']\n",
    "\n",
    "# impute the missing data on the test set\n",
    "TEST_X = df_test_features.drop(columns=['pid', 'Time']).reset_index(drop=True).fillna(df_test_features.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sub-Task 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training data into training and validation set and impute missing data\n",
    "X = df_train_features.drop(columns=['pid', 'Time']).reset_index(drop=True).fillna(df_train_features.mean())\n",
    "y_1 = labels_copied[LABELS1]\n",
    "X_train_1, X_val_1, y_train_1, y_val_1 = train_test_split(X, y_1, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84302875 0.74672505 0.71108954 0.71374089 0.71146423 0.75940477\n",
      " 0.81020476 0.78476432 0.78900523 0.90380658]\n",
      "Average score:  0.7773234137324464\n"
     ]
    }
   ],
   "source": [
    "# use a random forest classifier with every hour for every patient\n",
    "clf = RandomForestClassifier(n_estimators=300, class_weight=None, n_jobs=-1)\n",
    "clf.fit(X_train_1, y_train_1)\n",
    "y_pred_proba=clf.predict_proba(X_val_1)\n",
    "\n",
    "err = np.empty(10)\n",
    "list_proba=list()\n",
    "for i,label in enumerate(LABELS1):\n",
    "    err[i] = roc_auc_score(y_val_1[label], y_pred_proba[i][:,1])\n",
    "    list_proba.append(y_pred_proba[i][:,1])\n",
    "print(err)\n",
    "print('Average score: ', np.mean(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6163849342185341\n",
      "0.5757274397853795\n",
      "0.566577834241885\n",
      "0.5615395784524944\n",
      "0.5600832861647934\n",
      "0.5949277906930227\n",
      "0.5949529645965884\n",
      "0.5975596268326568\n",
      "0.6769628863276752\n",
      "0.7045208264773636\n",
      "Average Score:  0.6049237167790393\n"
     ]
    }
   ],
   "source": [
    "err = np.empty(10)\n",
    "for i, labels in enumerate(LABELS1):\n",
    "    y_val_reduced = y_val_1[labels][0:len(y_val_1[labels]):12]\n",
    "    y_pred_proba_reduced = np.empty(int(len(y_pred_proba[i][:,1])/12))\n",
    "    counter = 0\n",
    "    for splits in np.split(np.array(y_pred_proba[i][:,1]), int(len(y_pred_proba[i][:,1])/12)):\n",
    "        y_pred_proba_reduced[counter] = splits.mean() \n",
    "        counter = counter+1\n",
    "    err[i] = roc_auc_score(y_val_reduced, y_pred_proba_reduced)\n",
    "    print(err[i])\n",
    "print('Average Score: ', np.mean(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_y_pred_proba = clf.predict_proba(TEST_X)\n",
    "\n",
    "TEST_list_proba = list()\n",
    "for j in range(10):\n",
    "    TEST_y_pred_proba_reduced = np.empty(int(len(TEST_y_pred_proba[j][:,1])/12))\n",
    "    counter = 0\n",
    "    for splits in np.split(np.array(TEST_y_pred_proba[j][:,1]), int(len(TEST_y_pred_proba[j][:,1])/12)):\n",
    "        TEST_y_pred_proba_reduced[counter] = splits.mean() \n",
    "        counter = counter+1\n",
    "    TEST_list_proba.append(TEST_y_pred_proba_reduced)\n",
    "proba_subtask1 = TEST_list_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sub-Task 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training data into training and validation set and impute missing data\n",
    "y_2 = labels_copied[LABELS2]\n",
    "X_train_2, X_val_2, y_train_2, y_val_2 = train_test_split(X, y_2, test_size=0.01, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidschwartz/opt/anaconda3/envs/intro-ml/lib/python3.7/site-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7499531661392891\n"
     ]
    }
   ],
   "source": [
    "# use a random forest classifier with every hour for every patient\n",
    "clf = RandomForestClassifier(n_estimators=300, class_weight=None, n_jobs=-1)\n",
    "\n",
    "clf.fit(X_train_2, y_train_2)\n",
    "y_pred_proba = clf.predict_proba(X_val_2)\n",
    "err = roc_auc_score(y_val_2, y_pred_proba[:,1])\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_y_pred_proba = clf.predict_proba(TEST_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_y_pred_proba_reduced = np.empty(int(len(TEST_y_pred_proba[:,1])/12))\n",
    "counter = 0\n",
    "for splits in np.split(np.array(TEST_y_pred_proba[:,1]), int(len(TEST_y_pred_proba[:,1])/12)):\n",
    "    TEST_y_pred_proba_reduced[counter] = splits.mean() \n",
    "    counter = counter+1\n",
    "proba_subtask2 = TEST_y_pred_proba_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sub-Task 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training data into training and validation set and impute missing data\n",
    "y_3 = labels_copied[LABELS3]\n",
    "X_train_3, X_val_3, y_train_3, y_val_3 = train_test_split(X, y_3, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29355174609634227\n"
     ]
    }
   ],
   "source": [
    "kf = RepeatedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "model = RidgeCV(alphas=(0.1, 1, 10), scoring='r2', cv=kf)\n",
    "\n",
    "model.fit(X_train_3, y_train_3)\n",
    "y_pred = model.predict(X_val_3)\n",
    "print(r2_score(y_val_3, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02034172374344556\n",
      "0.03348940686420532\n",
      "0.02133598799664138\n",
      "0.03279945487074065\n"
     ]
    }
   ],
   "source": [
    "for i, labels in enumerate(LABELS3):\n",
    "    y_test_reduced = y_val_3[labels][0:len(y_val_3[labels]):12]\n",
    "    y_pred_reduced = np.empty(int(len(y_pred[:,i])/12))\n",
    "    counter = 0\n",
    "    for splits in np.split(np.array(y_pred[:,i]), int(len(y_pred[:,i])/12)):\n",
    "        y_pred_reduced[counter] = splits.mean() \n",
    "        counter = counter+1\n",
    "    print(r2_score(y_test_reduced, y_pred_reduced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18.43489729 84.75657179 97.17780483 85.23306489]\n",
      " [16.54211997 80.69237988 98.10692822 80.703822  ]\n",
      " [16.4183435  83.4694375  98.01750034 83.04454697]\n",
      " ...\n",
      " [18.15093592 77.11419336 97.74942134 87.73480906]\n",
      " [18.44904101 79.13707552 97.75810323 87.91817959]\n",
      " [17.45656539 77.23737213 97.7670354  86.62373098]]\n"
     ]
    }
   ],
   "source": [
    "TEST_y_pred_values = model.predict(TEST_X)\n",
    "print(TEST_y_pred_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_list_values = list()\n",
    "for j in range(4):\n",
    "    TEST_y_pred_values_reduced = np.empty(int(len(TEST_y_pred_values[:,j])/12))\n",
    "    counter = 0\n",
    "    for splits in np.split(np.array(TEST_y_pred_values[:,j]), int(len(TEST_y_pred_values[:,j])/12)):\n",
    "        TEST_y_pred_values_reduced[counter] = splits.mean() \n",
    "        counter = counter+1\n",
    "    TEST_list_values.append(TEST_y_pred_values_reduced)\n",
    "proba_subtask3=TEST_list_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'sample.zip'\n",
    "df_submission = pd.read_csv(filename)\n",
    "\n",
    "for i,label in enumerate(LABELS1):\n",
    "    # round classification labels\n",
    "    df_submission[label] = proba_subtask1[i]\n",
    "df_submission[LABELS2[0]] = proba_subtask2\n",
    "\n",
    "for i,label in enumerate(LABELS3):\n",
    "    # round classification labels\n",
    "    df_submission[label]=proba_subtask3[i]\n",
    "\n",
    "df_submission.to_csv('submission.csv',index=False)\n",
    "df_submission.to_csv('prediction.zip', index=False, float_format='%.3f', compression='zip')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7df4d15e59cac213afef75c805c6c35b948ade230879836dc77c436b6318e246"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('intro-ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
