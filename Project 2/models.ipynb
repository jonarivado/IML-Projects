{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Special about this task:\n",
    "#\n",
    "# missing features and imbalanced classification, predicting rarely-occuring events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>EtCO2</th>\n",
       "      <th>PTT</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Lactate</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Hgb</th>\n",
       "      <th>HCO3</th>\n",
       "      <th>BaseExcess</th>\n",
       "      <th>RRate</th>\n",
       "      <th>...</th>\n",
       "      <th>Alkalinephos</th>\n",
       "      <th>SpO2</th>\n",
       "      <th>Bilirubin_direct</th>\n",
       "      <th>Chloride</th>\n",
       "      <th>Hct</th>\n",
       "      <th>Heartrate</th>\n",
       "      <th>Bilirubin_total</th>\n",
       "      <th>TroponinI</th>\n",
       "      <th>ABPs</th>\n",
       "      <th>pH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.0</td>\n",
       "      <td>32.829817</td>\n",
       "      <td>38.801443</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.383041</td>\n",
       "      <td>36.750000</td>\n",
       "      <td>8.566667</td>\n",
       "      <td>25.333333</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>96.675671</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.170195</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>23.200000</td>\n",
       "      <td>77.083333</td>\n",
       "      <td>1.544023</td>\n",
       "      <td>6.414359</td>\n",
       "      <td>114.500000</td>\n",
       "      <td>7.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86.0</td>\n",
       "      <td>32.829817</td>\n",
       "      <td>31.800000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2.383041</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>23.801594</td>\n",
       "      <td>-0.789992</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>96.675671</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>1.170195</td>\n",
       "      <td>105.925903</td>\n",
       "      <td>40.200000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>1.544023</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>131.181818</td>\n",
       "      <td>7.375355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.0</td>\n",
       "      <td>32.829817</td>\n",
       "      <td>34.600000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.383041</td>\n",
       "      <td>36.666667</td>\n",
       "      <td>10.550000</td>\n",
       "      <td>23.801594</td>\n",
       "      <td>-0.789992</td>\n",
       "      <td>14.636364</td>\n",
       "      <td>...</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>99.272727</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>105.925903</td>\n",
       "      <td>33.550000</td>\n",
       "      <td>72.545455</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>125.454545</td>\n",
       "      <td>7.375355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66.0</td>\n",
       "      <td>32.829817</td>\n",
       "      <td>53.800000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>37.166667</td>\n",
       "      <td>10.316667</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>-2.857143</td>\n",
       "      <td>15.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>96.675671</td>\n",
       "      <td>99.333333</td>\n",
       "      <td>1.170195</td>\n",
       "      <td>113.500000</td>\n",
       "      <td>30.390000</td>\n",
       "      <td>87.333333</td>\n",
       "      <td>1.544023</td>\n",
       "      <td>6.414359</td>\n",
       "      <td>100.666667</td>\n",
       "      <td>7.352857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42.0</td>\n",
       "      <td>32.829817</td>\n",
       "      <td>38.801443</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2.383041</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>10.748832</td>\n",
       "      <td>23.801594</td>\n",
       "      <td>-0.789992</td>\n",
       "      <td>17.181818</td>\n",
       "      <td>...</td>\n",
       "      <td>96.675671</td>\n",
       "      <td>97.800000</td>\n",
       "      <td>1.170195</td>\n",
       "      <td>105.925903</td>\n",
       "      <td>32.005177</td>\n",
       "      <td>81.181818</td>\n",
       "      <td>1.544023</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>204.545455</td>\n",
       "      <td>7.375355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18990</th>\n",
       "      <td>52.0</td>\n",
       "      <td>32.829817</td>\n",
       "      <td>25.800000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>22.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.545455</td>\n",
       "      <td>...</td>\n",
       "      <td>96.675671</td>\n",
       "      <td>96.181818</td>\n",
       "      <td>1.170195</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>31.560000</td>\n",
       "      <td>108.272727</td>\n",
       "      <td>1.544023</td>\n",
       "      <td>6.414359</td>\n",
       "      <td>87.333333</td>\n",
       "      <td>7.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18991</th>\n",
       "      <td>66.0</td>\n",
       "      <td>32.829817</td>\n",
       "      <td>38.801443</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.383041</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>11.200000</td>\n",
       "      <td>23.801594</td>\n",
       "      <td>-0.789992</td>\n",
       "      <td>16.909091</td>\n",
       "      <td>...</td>\n",
       "      <td>96.675671</td>\n",
       "      <td>96.090909</td>\n",
       "      <td>1.170195</td>\n",
       "      <td>105.925903</td>\n",
       "      <td>34.600000</td>\n",
       "      <td>92.909091</td>\n",
       "      <td>1.544023</td>\n",
       "      <td>6.414359</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>7.375355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18992</th>\n",
       "      <td>44.0</td>\n",
       "      <td>32.829817</td>\n",
       "      <td>38.801443</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.383041</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>-3.500000</td>\n",
       "      <td>24.900000</td>\n",
       "      <td>...</td>\n",
       "      <td>96.675671</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.170195</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>36.700000</td>\n",
       "      <td>99.100000</td>\n",
       "      <td>1.544023</td>\n",
       "      <td>6.414359</td>\n",
       "      <td>100.300000</td>\n",
       "      <td>7.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18993</th>\n",
       "      <td>70.0</td>\n",
       "      <td>32.829817</td>\n",
       "      <td>38.801443</td>\n",
       "      <td>23.000573</td>\n",
       "      <td>2.383041</td>\n",
       "      <td>36.500000</td>\n",
       "      <td>10.748832</td>\n",
       "      <td>23.801594</td>\n",
       "      <td>-0.789992</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>96.675671</td>\n",
       "      <td>99.100000</td>\n",
       "      <td>1.170195</td>\n",
       "      <td>105.925903</td>\n",
       "      <td>32.005177</td>\n",
       "      <td>64.400000</td>\n",
       "      <td>1.544023</td>\n",
       "      <td>6.414359</td>\n",
       "      <td>110.500000</td>\n",
       "      <td>7.375355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18994</th>\n",
       "      <td>60.0</td>\n",
       "      <td>32.829817</td>\n",
       "      <td>38.801443</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.383041</td>\n",
       "      <td>36.500000</td>\n",
       "      <td>14.400000</td>\n",
       "      <td>23.801594</td>\n",
       "      <td>-0.789992</td>\n",
       "      <td>18.126663</td>\n",
       "      <td>...</td>\n",
       "      <td>96.675671</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>1.170195</td>\n",
       "      <td>105.925903</td>\n",
       "      <td>40.200000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>1.544023</td>\n",
       "      <td>6.414359</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>7.375355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18995 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age      EtCO2        PTT        BUN   Lactate       Temp        Hgb  \\\n",
       "0      34.0  32.829817  38.801443  12.000000  2.383041  36.750000   8.566667   \n",
       "1      86.0  32.829817  31.800000  32.000000  2.383041  36.000000  13.100000   \n",
       "2      66.0  32.829817  34.600000   8.000000  2.383041  36.666667  10.550000   \n",
       "3      66.0  32.829817  53.800000  32.000000  1.800000  37.166667  10.316667   \n",
       "4      42.0  32.829817  38.801443  18.000000  2.383041  36.000000  10.748832   \n",
       "...     ...        ...        ...        ...       ...        ...        ...   \n",
       "18990  52.0  32.829817  25.800000  11.000000  1.700000  36.000000   9.500000   \n",
       "18991  66.0  32.829817  38.801443  33.000000  2.383041  37.500000  11.200000   \n",
       "18992  44.0  32.829817  38.801443  15.000000  2.383041  38.000000  12.400000   \n",
       "18993  70.0  32.829817  38.801443  23.000573  2.383041  36.500000  10.748832   \n",
       "18994  60.0  32.829817  38.801443  13.000000  2.383041  36.500000  14.400000   \n",
       "\n",
       "            HCO3  BaseExcess      RRate  ...  Alkalinephos        SpO2  \\\n",
       "0      25.333333   -0.666667  17.000000  ...     96.675671  100.000000   \n",
       "1      23.801594   -0.789992  18.000000  ...     96.675671   96.000000   \n",
       "2      23.801594   -0.789992  14.636364  ...    130.000000   99.272727   \n",
       "3      19.500000   -2.857143  15.833333  ...     96.675671   99.333333   \n",
       "4      23.801594   -0.789992  17.181818  ...     96.675671   97.800000   \n",
       "...          ...         ...        ...  ...           ...         ...   \n",
       "18990  22.666667    0.000000  15.545455  ...     96.675671   96.181818   \n",
       "18991  23.801594   -0.789992  16.909091  ...     96.675671   96.090909   \n",
       "18992  24.000000   -3.500000  24.900000  ...     96.675671  100.000000   \n",
       "18993  23.801594   -0.789992  15.500000  ...     96.675671   99.100000   \n",
       "18994  23.801594   -0.789992  18.126663  ...     96.675671   96.000000   \n",
       "\n",
       "       Bilirubin_direct    Chloride        Hct   Heartrate  Bilirubin_total  \\\n",
       "0              1.170195  112.000000  23.200000   77.083333         1.544023   \n",
       "1              1.170195  105.925903  40.200000   59.000000         1.544023   \n",
       "2              0.100000  105.925903  33.550000   72.545455         0.600000   \n",
       "3              1.170195  113.500000  30.390000   87.333333         1.544023   \n",
       "4              1.170195  105.925903  32.005177   81.181818         1.544023   \n",
       "...                 ...         ...        ...         ...              ...   \n",
       "18990          1.170195  106.000000  31.560000  108.272727         1.544023   \n",
       "18991          1.170195  105.925903  34.600000   92.909091         1.544023   \n",
       "18992          1.170195   97.000000  36.700000   99.100000         1.544023   \n",
       "18993          1.170195  105.925903  32.005177   64.400000         1.544023   \n",
       "18994          1.170195  105.925903  40.200000   68.000000         1.544023   \n",
       "\n",
       "       TroponinI        ABPs        pH  \n",
       "0       6.414359  114.500000  7.370000  \n",
       "1       0.440000  131.181818  7.375355  \n",
       "2       0.020000  125.454545  7.375355  \n",
       "3       6.414359  100.666667  7.352857  \n",
       "4       0.080000  204.545455  7.375355  \n",
       "...          ...         ...       ...  \n",
       "18990   6.414359   87.333333  7.330000  \n",
       "18991   6.414359  165.000000  7.375355  \n",
       "18992   6.414359  100.300000  7.300000  \n",
       "18993   6.414359  110.500000  7.375355  \n",
       "18994   6.414359  133.000000  7.375355  \n",
       "\n",
       "[18995 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#load dataset\n",
    "train_features_data=pd.read_csv('train_features.csv')\n",
    "labels_data=pd.read_csv('train_labels.csv')\n",
    "#extract features with pandas groupby method\n",
    "train_data=pd.DataFrame(train_features_data.groupby(['pid']).mean())\n",
    "train=train_data.reset_index().drop(columns=['pid', 'Time']).fillna(train_data.mean()) #assumed that time plays no role on predictions\n",
    "display(train)\n",
    "#labels=labels_data.drop(columns=['pid'])\n",
    "labels1 = labels_data[['LABEL_BaseExcess', 'LABEL_Fibrinogen', 'LABEL_AST', 'LABEL_Alkalinephos', 'LABEL_Bilirubin_total', 'LABEL_Lactate', 'LABEL_TroponinI', 'LABEL_SaO2', 'LABEL_Bilirubin_direct', 'LABEL_EtCO2']]\n",
    "labels2 = labels_data[['LABEL_Sepsis']]\n",
    "labels3 = labels_data[['LABEL_RRate', 'LABEL_ABPm', 'LABEL_SpO2', 'LABEL_Heartrate']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtask1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3670680975661088\n",
      "[[0.27277674 0.07701021 0.25395403 ... 0.24317755 0.04672681 0.07147905]\n",
      " [0.25462353 0.04259344 0.23347652 ... 0.25744897 0.05082636 0.04114712]\n",
      " [0.2724582  0.07844939 0.24926045 ... 0.2203056  0.04331503 0.05679011]\n",
      " ...\n",
      " [0.26386166 0.05133288 0.26701203 ... 0.24097621 0.04524302 0.06147501]\n",
      " [0.26618286 0.07113257 0.21848341 ... 0.20402182 0.03556564 0.06705919]\n",
      " [0.24175538 0.04973555 0.20991926 ... 0.21775481 0.04314602 0.0710091 ]]\n"
     ]
    }
   ],
   "source": [
    "#Linear Regression model\n",
    "#split into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, labels1, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred=pd.DataFrame(model.predict(X_test))\n",
    "err=np.sqrt(mean_squared_error(y_pred,y_test))\n",
    "print(err)\n",
    "print(model.predict(X_test))\n",
    "#y_pred.to_csv('prediction.zip', index=False, float_format='%.3f', compression='zip')\n",
    "y_pred.to_csv('submission.csv', index=False, header= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manue\\anaconda3\\envs\\MLenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.81798885e-01, 1.82011004e-02, 1.43499227e-08],\n",
       "       [9.71721788e-01, 2.82781823e-02, 3.00194617e-08],\n",
       "       [9.85449423e-01, 1.45505647e-02, 1.22616229e-08],\n",
       "       [9.76296778e-01, 2.37031826e-02, 3.95217425e-08],\n",
       "       [9.85386872e-01, 1.46131162e-02, 1.18792868e-08],\n",
       "       [9.70466976e-01, 2.95329508e-02, 7.31355450e-08],\n",
       "       [9.86890591e-01, 1.31093893e-02, 1.98716082e-08],\n",
       "       [9.76400810e-01, 2.35991622e-02, 2.74875030e-08],\n",
       "       [9.79843687e-01, 2.01562825e-02, 3.05344325e-08],\n",
       "       [9.69131799e-01, 3.08681693e-02, 3.14925519e-08],\n",
       "       [9.76504394e-01, 2.34955873e-02, 1.91176405e-08],\n",
       "       [9.75412640e-01, 2.45873167e-02, 4.36246785e-08],\n",
       "       [9.74557642e-01, 2.54423370e-02, 2.13792130e-08],\n",
       "       [9.91972830e-01, 8.02716625e-03, 3.87385241e-09],\n",
       "       [9.88201051e-01, 1.17989458e-02, 2.79175236e-09],\n",
       "       [9.86774747e-01, 1.32252408e-02, 1.27151873e-08],\n",
       "       [9.88115246e-01, 1.18847450e-02, 9.14773174e-09],\n",
       "       [9.81554758e-01, 1.84452224e-02, 1.95932485e-08],\n",
       "       [9.56586246e-01, 4.34136855e-02, 6.80415498e-08],\n",
       "       [9.84122383e-01, 1.58775968e-02, 2.04130019e-08],\n",
       "       [9.46770883e-01, 5.32290308e-02, 8.59647831e-08],\n",
       "       [9.81748269e-01, 1.82516982e-02, 3.27004961e-08],\n",
       "       [9.96007987e-01, 3.99201138e-03, 1.30483902e-09],\n",
       "       [9.52329307e-01, 4.76704572e-02, 2.36239963e-07],\n",
       "       [9.51865333e-01, 4.81344622e-02, 2.05163836e-07],\n",
       "       [9.51562112e-01, 4.84378015e-02, 8.64830409e-08],\n",
       "       [9.69629634e-01, 3.03702800e-02, 8.60009593e-08],\n",
       "       [9.74933015e-01, 2.50669599e-02, 2.48184225e-08],\n",
       "       [9.77350184e-01, 2.26497990e-02, 1.73189141e-08],\n",
       "       [9.71230870e-01, 2.87690714e-02, 5.82394860e-08],\n",
       "       [9.64293086e-01, 3.57068438e-02, 7.01047655e-08],\n",
       "       [9.64954846e-01, 3.50450964e-02, 5.72784802e-08],\n",
       "       [9.88382343e-01, 1.16176503e-02, 6.97220631e-09],\n",
       "       [9.89069180e-01, 1.09308152e-02, 5.25993594e-09],\n",
       "       [9.68723181e-01, 3.12767758e-02, 4.29921922e-08],\n",
       "       [9.84669798e-01, 1.53301940e-02, 7.95205586e-09],\n",
       "       [9.78956591e-01, 2.10433993e-02, 9.57585453e-09],\n",
       "       [9.86870851e-01, 1.31291408e-02, 8.44825740e-09],\n",
       "       [9.85854838e-01, 1.41451461e-02, 1.54687067e-08],\n",
       "       [9.74109378e-01, 2.58905935e-02, 2.82765730e-08],\n",
       "       [9.86631796e-01, 1.33681925e-02, 1.13077097e-08],\n",
       "       [9.62246755e-01, 3.77531794e-02, 6.60579457e-08],\n",
       "       [9.89018719e-01, 1.09812693e-02, 1.12248994e-08],\n",
       "       [9.72468128e-01, 2.75317351e-02, 1.36826754e-07],\n",
       "       [9.60265525e-01, 3.97342540e-02, 2.21439918e-07],\n",
       "       [9.73875846e-01, 2.61241142e-02, 3.98490116e-08],\n",
       "       [9.80321302e-01, 1.96786726e-02, 2.51490624e-08],\n",
       "       [9.83347736e-01, 1.66522437e-02, 2.00433047e-08],\n",
       "       [9.78588516e-01, 2.14114654e-02, 1.85801115e-08],\n",
       "       [9.78679538e-01, 2.13204432e-02, 1.91786808e-08],\n",
       "       [2.11773017e-03, 8.74346512e-01, 1.23535757e-01],\n",
       "       [5.77997964e-03, 8.59937045e-01, 1.34282975e-01],\n",
       "       [1.05446197e-03, 7.25633677e-01, 2.73311861e-01],\n",
       "       [1.53572530e-02, 9.39295295e-01, 4.53474516e-02],\n",
       "       [2.36454678e-03, 8.14766029e-01, 1.82869424e-01],\n",
       "       [6.91843185e-03, 8.60184475e-01, 1.32897093e-01],\n",
       "       [3.73740794e-03, 7.17196182e-01, 2.79066410e-01],\n",
       "       [1.47584383e-01, 8.49329881e-01, 3.08573655e-03],\n",
       "       [2.76420376e-03, 8.96724746e-01, 1.00511050e-01],\n",
       "       [4.11932995e-02, 9.11870439e-01, 4.69362615e-02],\n",
       "       [5.57801575e-02, 9.37662057e-01, 6.55778538e-03],\n",
       "       [1.50803940e-02, 8.98695335e-01, 8.62242714e-02],\n",
       "       [9.09585422e-03, 9.76453769e-01, 1.44503766e-02],\n",
       "       [3.02245892e-03, 7.79472120e-01, 2.17505421e-01],\n",
       "       [7.42917997e-02, 9.15191949e-01, 1.05162509e-02],\n",
       "       [5.26570274e-03, 9.26375749e-01, 6.83585480e-02],\n",
       "       [8.61815185e-03, 7.74772719e-01, 2.16609129e-01],\n",
       "       [1.63660887e-02, 9.65253317e-01, 1.83805948e-02],\n",
       "       [1.80278409e-03, 7.99253598e-01, 1.98943618e-01],\n",
       "       [2.38876039e-02, 9.59414164e-01, 1.66982318e-02],\n",
       "       [2.27792443e-03, 4.40343058e-01, 5.57379018e-01],\n",
       "       [1.67901850e-02, 9.56693788e-01, 2.65160271e-02],\n",
       "       [7.08946740e-04, 5.95311777e-01, 4.03979276e-01],\n",
       "       [3.01496147e-03, 8.60214294e-01, 1.36770745e-01],\n",
       "       [7.05132094e-03, 9.42909633e-01, 5.00390460e-02],\n",
       "       [5.05909898e-03, 9.20049954e-01, 7.48909467e-02],\n",
       "       [1.11460504e-03, 8.01458675e-01, 1.97426720e-01],\n",
       "       [5.73926106e-04, 4.81125658e-01, 5.18300416e-01],\n",
       "       [5.43899206e-03, 8.12858827e-01, 1.81702181e-01],\n",
       "       [6.17120755e-02, 9.34885084e-01, 3.40284046e-03],\n",
       "       [2.90769183e-02, 9.57201460e-01, 1.37216218e-02],\n",
       "       [3.70996681e-02, 9.55311032e-01, 7.58930008e-03],\n",
       "       [2.51047084e-02, 9.56463029e-01, 1.84322630e-02],\n",
       "       [4.43685188e-04, 3.49565079e-01, 6.49991236e-01],\n",
       "       [1.01029948e-02, 7.51066958e-01, 2.38830048e-01],\n",
       "       [9.89056017e-03, 7.89306633e-01, 2.00802807e-01],\n",
       "       [2.25125353e-03, 8.05392087e-01, 1.92356659e-01],\n",
       "       [2.75737115e-03, 9.12544930e-01, 8.46976993e-02],\n",
       "       [2.68560321e-02, 9.28687724e-01, 4.44562438e-02],\n",
       "       [1.98151269e-02, 9.37862197e-01, 4.23226762e-02],\n",
       "       [8.63916145e-03, 8.97821705e-01, 9.35391334e-02],\n",
       "       [4.60588927e-03, 8.28503791e-01, 1.66890320e-01],\n",
       "       [1.75190347e-02, 9.56934803e-01, 2.55461627e-02],\n",
       "       [1.21663005e-01, 8.75252952e-01, 3.08404292e-03],\n",
       "       [1.43653412e-02, 9.20342358e-01, 6.52923005e-02],\n",
       "       [1.98315969e-02, 9.38302922e-01, 4.18654811e-02],\n",
       "       [1.69751658e-02, 9.25479667e-01, 5.75451673e-02],\n",
       "       [8.45649963e-03, 9.35101111e-01, 5.64423898e-02],\n",
       "       [2.43978579e-01, 7.54714210e-01, 1.30721139e-03],\n",
       "       [1.90475060e-02, 9.36005152e-01, 4.49473417e-02],\n",
       "       [8.85697115e-07, 3.92300058e-03, 9.96076114e-01],\n",
       "       [2.38688814e-04, 1.61970636e-01, 8.37790675e-01],\n",
       "       [2.45105547e-06, 2.56135382e-02, 9.74384011e-01],\n",
       "       [3.08128455e-05, 8.19132638e-02, 9.18055923e-01],\n",
       "       [3.67403554e-06, 1.74491041e-02, 9.82547222e-01],\n",
       "       [5.47528936e-08, 4.67040252e-03, 9.95329543e-01],\n",
       "       [5.67608697e-03, 5.11803248e-01, 4.82520665e-01],\n",
       "       [6.16141461e-07, 2.15012045e-02, 9.78498179e-01],\n",
       "       [5.15477701e-06, 5.32304810e-02, 9.46764364e-01],\n",
       "       [6.45661016e-07, 5.77426138e-03, 9.94225093e-01],\n",
       "       [2.98572480e-04, 2.10398646e-01, 7.89302781e-01],\n",
       "       [7.17040017e-05, 1.36871957e-01, 8.63056339e-01],\n",
       "       [2.09855403e-05, 6.51771401e-02, 9.34801874e-01],\n",
       "       [2.24873594e-04, 1.44122436e-01, 8.55652690e-01],\n",
       "       [6.74591883e-05, 4.30966373e-02, 9.56835904e-01],\n",
       "       [5.07709908e-05, 5.39011022e-02, 9.46048127e-01],\n",
       "       [5.49643389e-05, 1.23246874e-01, 8.76698161e-01],\n",
       "       [8.41744536e-08, 3.61982710e-03, 9.96380089e-01],\n",
       "       [3.10209920e-09, 1.00163153e-03, 9.98998365e-01],\n",
       "       [3.84910243e-04, 4.50296389e-01, 5.49318701e-01],\n",
       "       [5.52097243e-06, 2.38490194e-02, 9.76145460e-01],\n",
       "       [6.02572668e-04, 1.89553203e-01, 8.09844224e-01],\n",
       "       [3.10549440e-08, 4.68362320e-03, 9.95316346e-01],\n",
       "       [5.78777036e-04, 3.91722468e-01, 6.07698755e-01],\n",
       "       [1.26767742e-05, 3.87677257e-02, 9.61219597e-01],\n",
       "       [4.82223383e-06, 5.19262883e-02, 9.48068889e-01],\n",
       "       [1.06045312e-03, 4.55232929e-01, 5.43706617e-01],\n",
       "       [1.01060190e-03, 3.85031263e-01, 6.13958135e-01],\n",
       "       [1.04732990e-05, 3.62516463e-02, 9.63737880e-01],\n",
       "       [1.67815323e-05, 1.42875134e-01, 8.57108085e-01],\n",
       "       [1.05323815e-06, 2.92799499e-02, 9.70718997e-01],\n",
       "       [7.01594908e-07, 1.77002432e-02, 9.82299055e-01],\n",
       "       [7.74100728e-06, 2.71603875e-02, 9.72831872e-01],\n",
       "       [5.23446489e-04, 4.75943507e-01, 5.23533046e-01],\n",
       "       [6.19081553e-05, 1.89356960e-01, 8.10581132e-01],\n",
       "       [3.88662150e-07, 1.17393501e-02, 9.88260261e-01],\n",
       "       [1.14215237e-05, 1.73518547e-02, 9.82636724e-01],\n",
       "       [6.68861459e-05, 1.19975352e-01, 8.79957762e-01],\n",
       "       [1.60125201e-03, 4.39869442e-01, 5.58529306e-01],\n",
       "       [3.91999772e-05, 9.33829555e-02, 9.06577845e-01],\n",
       "       [6.19743376e-06, 2.02263124e-02, 9.79767490e-01],\n",
       "       [9.83084388e-05, 1.19950828e-01, 8.79950864e-01],\n",
       "       [2.38688814e-04, 1.61970636e-01, 8.37790675e-01],\n",
       "       [2.01827101e-06, 1.26107382e-02, 9.87387244e-01],\n",
       "       [3.74491238e-06, 1.20915019e-02, 9.87904753e-01],\n",
       "       [5.50431768e-05, 7.96239028e-02, 9.20321054e-01],\n",
       "       [2.23826251e-04, 2.50267731e-01, 7.49508443e-01],\n",
       "       [1.36560044e-04, 1.56837244e-01, 8.43026196e-01],\n",
       "       [4.49024305e-05, 3.84733249e-02, 9.61481773e-01],\n",
       "       [4.68956774e-04, 2.35011411e-01, 7.64519632e-01]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = LogisticRegression(random_state=0).fit(X, y)\n",
    "y_pred=clf.predict_proba(X)\n",
    "display(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36682697387567126\n"
     ]
    }
   ],
   "source": [
    "#Linear LassoCV Regression model\n",
    "from sklearn.linear_model import LassoCV\n",
    "#split into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, labels1, test_size=0.2, random_state=42)\n",
    "\n",
    "model = MultiOutputRegressor(LassoCV(alphas = np.linspace(0.1,100,100), fit_intercept=False, max_iter=300000, cv=10, random_state=0))\n",
    "model.fit(X_train, y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "err=np.sqrt(mean_squared_error(y_pred,y_test))\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40009475055732824\n"
     ]
    }
   ],
   "source": [
    "#Knearest neighbour\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, labels1, test_size=0.2, random_state=42)\n",
    "model = KNeighborsRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "err=np.sqrt(mean_squared_error(y_pred,y_test))\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5263521551283064\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, labels1, test_size=0.2, random_state=42)\n",
    "model = DecisionTreeRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "err=np.sqrt(mean_squared_error(y_pred,y_test))\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree with cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "#from sklearn.model_selection import RepeatedKFold\n",
    "#cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "kf = KFold(n_splits=10, random_state=0, shuffle=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, labels1, test_size=0.2, random_state=42)\n",
    "model = DecisionTreeRegressor()\n",
    "result = cross_val_score(model, X_train, y_train, scoring='neg_root_mean_squared_error', cv = kf)\n",
    "result = np.absolute(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manue\\anaconda3\\envs\\MLenv\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Manue\\anaconda3\\envs\\MLenv\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Manue\\anaconda3\\envs\\MLenv\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Manue\\anaconda3\\envs\\MLenv\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Manue\\anaconda3\\envs\\MLenv\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Manue\\anaconda3\\envs\\MLenv\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Manue\\anaconda3\\envs\\MLenv\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Manue\\anaconda3\\envs\\MLenv\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Manue\\anaconda3\\envs\\MLenv\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6374500646573907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manue\\anaconda3\\envs\\MLenv\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#SVR\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, labels1, test_size=0.2, random_state=42)\n",
    "model = MultiOutputRegressor(LinearSVR())\n",
    "model.fit(X_train, y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "err=np.sqrt(mean_squared_error(y_pred,y_test))\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n",
      "[[0.11249495 0.08698821 0.10991488 ... 0.10844697 0.0833467  0.08631727]\n",
      " [0.11186247 0.08425402 0.10894238 ... 0.11225211 0.08524785 0.08408117]\n",
      " [0.1133615  0.08787521 0.1101609  ... 0.10621745 0.08361958 0.08523684]\n",
      " ...\n",
      " [0.11163303 0.08417308 0.11206669 ... 0.10850341 0.08344665 0.08539107]\n",
      " [0.11429744 0.08838062 0.10767209 ... 0.10569842 0.08403066 0.08787437]\n",
      " [0.11177811 0.08642708 0.10735681 ... 0.10843585 0.08561927 0.08906605]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "#split into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, labels1, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RidgeClassifierCV(cv=10)\n",
    "model.fit(X_train, y_train)\n",
    "#y_pred=model.predict(X_test)\n",
    "print(model.predict(X_test)[0:20])\n",
    "print(model._predict_proba_lr(X_test))\n",
    "# err=np.sqrt(mean_squared_error(y_pred,y_test))\n",
    "# print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44182492640887694\n"
     ]
    }
   ],
   "source": [
    "#KNeighborsClassifier\n",
    "#split into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, labels1, test_size=0.2, random_state=42)\n",
    "model = MultiOutputClassifier(KNeighborsClassifier())\n",
    "model.fit(X_train, y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "err=np.sqrt(mean_squared_error(y_pred,y_test))\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5289960294346954\n"
     ]
    }
   ],
   "source": [
    "#DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#split into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, labels1, test_size=0.2, random_state=42)\n",
    "model = DecisionTreeClassifier(random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "err=np.sqrt(mean_squared_error(y_pred,y_test))\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtask 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22870411765179602\n"
     ]
    }
   ],
   "source": [
    "#Linear Regression model\n",
    "#split into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, labels2, test_size=0.2, random_state=42)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "err=np.sqrt(mean_squared_error(y_pred,y_test))\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtask3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.893299105311838\n"
     ]
    }
   ],
   "source": [
    "#Linear Regression model\n",
    "#split into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, labels3, test_size=0.2, random_state=42)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "err=np.sqrt(mean_squared_error(y_pred,y_test))\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### help-functions provided for task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "clf = LogisticRegression(solver=\"liblinear\", random_state=0).fit(X, y)\n",
    "roc_auc_score(y, clf.predict_proba(X)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppose df is a pandas dataframe containing the result\n",
    "#df.to_csv('prediction.zip', index=False, float_format='%.3f', compression='zip')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "132ee69bdf725fa2e7e77068a76a4fd30f6a4e18b0c726e5d9906e9196537d1a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('MLenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
