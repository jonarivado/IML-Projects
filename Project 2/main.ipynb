{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_data=pd.read_csv('train_features.csv')\n",
    "train_labels_data=pd.read_csv('train_labels.csv')\n",
    "test_features_data=pd.read_csv('test_features.csv')\n",
    "# add labels with matching pid to features\n",
    "labels_copied = pd.DataFrame()\n",
    "labels_copied = labels_data.loc[labels_data.index.repeat(12)]\n",
    "labels_copied = labels_copied.drop(columns=['pid'])\n",
    "labels = train_labels_data.drop(columns=['pid'])\n",
    "LABELS1 = ['LABEL_BaseExcess', 'LABEL_Fibrinogen', 'LABEL_AST', 'LABEL_Alkalinephos', 'LABEL_Bilirubin_total',\n",
    "         'LABEL_Lactate', 'LABEL_TroponinI', 'LABEL_SaO2',\n",
    "         'LABEL_Bilirubin_direct', 'LABEL_EtCO2']\n",
    "LABELS2 = ['LABEL_Sepsis']\n",
    "LABELS3 = ['LABEL_RRate', 'LABEL_ABPm', 'LABEL_SpO2', 'LABEL_Heartrate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtask 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_features_data.drop(columns=['pid', 'Time']).reset_index(drop=True).fillna(train_features_data.mean())\n",
    "y = labels_copied[LABELS1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "TEST_X = test_features_data.drop(columns=['pid', 'Time']).reset_index(drop=True).fillna(test_features_data.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest model and Roc_Auc_Score using every hour per patient as sample for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74786978, 0.5923345 , 0.5963562 , 0.59884987, 0.59702855,\n",
       "       0.6257124 , 0.68203849, 0.65967371, 0.6067235 , 0.81680246])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf=RandomForestClassifier(class_weight='balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_proba=clf.predict_proba(X_test)\n",
    "err=np.empty(10)\n",
    "list_proba=list()\n",
    "for i,label in enumerate(LABELS1):\n",
    "    err[i]=roc_auc_score(y_test[label], y_pred_proba[i][:,1])\n",
    "    list_proba.append(y_pred_proba[i][:,1])\n",
    "display(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce values by 12 for test-labels and y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8574152308181227"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6448293418051483"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6434731937397924"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6467167228403896"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6484190142713141"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6860417733401605"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7343259345794392"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7293392139186532"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.627225061595162"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8934016740647396"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, labels in enumerate(LABELS1):\n",
    "    y_test_reduced=y_test[labels][0:len(y_test[labels]):12]\n",
    "    y_pred_proba_reduced=np.empty(int(len(y_pred_proba[i][:,1])/12))\n",
    "    counter=0\n",
    "    for splits in np.split(np.array(y_pred_proba[i][:,1]), int(len(y_pred_proba[i][:,1])/12)):\n",
    "        y_pred_proba_reduced[counter]=splits.mean() \n",
    "        counter=counter+1\n",
    "    display(roc_auc_score(y_test_reduced, y_pred_proba_reduced))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions for Test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_y_pred_proba=clf.predict_proba(TEST_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce values by 12 for TEST_y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_list_proba=list()\n",
    "for j in range(10):\n",
    "    TEST_y_pred_proba_reduced=np.empty(int(len(TEST_y_pred_proba[j][:,1])/12))\n",
    "    counter=0\n",
    "    for splits in np.split(np.array(TEST_y_pred_proba[j][:,1]), int(len(TEST_y_pred_proba[j][:,1])/12)):\n",
    "        TEST_y_pred_proba_reduced[counter]=splits.mean() \n",
    "        counter=counter+1\n",
    "    TEST_list_proba.append(TEST_y_pred_proba_reduced)\n",
    "proba_subtask1=TEST_list_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtask 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = labels_copied[LABELS2]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest model and Roc_Auc_Score using every hour per patient as sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manue\\anaconda3\\envs\\ML\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5890170964726441"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf=RandomForestClassifier(class_weight='balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_proba=clf.predict_proba(X_test)\n",
    "err=roc_auc_score(y_test, y_pred_proba[:,1])\n",
    "display(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction for Test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_y_pred_proba=clf.predict_proba(TEST_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce values by 12 for TEST_y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_y_pred_proba_reduced=np.empty(int(len(TEST_y_pred_proba[:,1])/12))\n",
    "counter=0\n",
    "for splits in np.split(np.array(TEST_y_pred_proba[:,1]), int(len(TEST_y_pred_proba[:,1])/12)):\n",
    "    TEST_y_pred_proba_reduced[counter]=splits.mean() \n",
    "    counter=counter+1\n",
    "proba_subtask2=TEST_y_pred_proba_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtask 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = labels_copied[LABELS3]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement MultiTaskLassoCV model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.06999034135672\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import MultiTaskLassoCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "model = MultiTaskLassoCV()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "print(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce values by 12 for test-labels and y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.867430176689115"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "82.66730564508838"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3.5784061454703764"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "95.78278255327055"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, labels in enumerate(LABELS3):\n",
    "    y_test_reduced=y_test[labels][0:len(y_test[labels]):12]\n",
    "    y_pred_reduced=np.empty(int(len(y_pred[:,i])/12))\n",
    "    counter=0\n",
    "    for splits in np.split(np.array(y_pred[:,i]), int(len(y_pred[:,i])/12)):\n",
    "        y_pred_reduced[counter]=splits.mean() \n",
    "        counter=counter+1\n",
    "    display(mean_squared_error(y_test_reduced, y_pred_reduced))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions for Test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18.41533445, 84.72553535, 97.17922627, 85.19909526],\n",
       "       [17.79360099, 83.31088506, 97.9080098 , 83.39845814],\n",
       "       [16.37547197, 83.86542909, 98.11785375, 82.16717108],\n",
       "       ...,\n",
       "       [18.13639543, 77.11627348, 97.70351645, 87.57104615],\n",
       "       [18.42553407, 79.14428665, 97.70518401, 87.82615071],\n",
       "       [17.45879352, 77.21650924, 97.72660432, 86.48475674]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TEST_y_pred_values=model.predict(TEST_X)\n",
    "display(TEST_y_pred_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce values by 12 for TEST_y_pred_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_list_values=list()\n",
    "for j in range(4):\n",
    "    TEST_y_pred_values_reduced=np.empty(int(len(TEST_y_pred_values[:,j])/12))\n",
    "    counter=0\n",
    "    for splits in np.split(np.array(TEST_y_pred_values[:,j]), int(len(TEST_y_pred_values[:,j])/12)):\n",
    "        TEST_y_pred_values_reduced[counter]=splits.mean() \n",
    "        counter=counter+1\n",
    "    TEST_list_values.append(TEST_y_pred_values_reduced)\n",
    "proba_subtask3=TEST_list_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write values into sample dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'sample.zip'\n",
    "df_submission = pd.read_csv(filename)\n",
    "for i,label in enumerate(LABELS1):\n",
    "    # round classification labels\n",
    "    df_submission[label]=proba_subtask1[i]\n",
    "df_submission[LABELS2[0]]=proba_subtask2\n",
    "for i,label in enumerate(LABELS3):\n",
    "    # round classification labels\n",
    "    df_submission[label]=proba_subtask3[i]\n",
    "df_submission.to_csv('submission.csv',index=False)\n",
    "df_submission.to_csv('prediction.zip', index=False, float_format='%.3f', compression='zip')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
