{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Dropout, Flatten, Convolution2D, MaxPooling2D,ZeroPadding2D\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## DATA ###########################\n",
    "\n",
    "# load and shape data as usual, but here we don't process class labels\n",
    "# to one-hot encoding. In fact, we don't exactly use class labels\n",
    "# during training, only while setting up the triplets.\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "\n",
    "def get_image(label, test=False):\n",
    "    \"\"\"Choose an image from our training or test data with the\n",
    "    given label.\"\"\"\n",
    "    if test:\n",
    "        y = y_test; X = X_test\n",
    "    else:\n",
    "        y = y_train; X = X_train\n",
    "    idx = np.random.randint(len(y))\n",
    "    while y[idx] != label:\n",
    "        # keep searching randomly!\n",
    "        idx = np.random.randint(len(y))\n",
    "    return X[idx]\n",
    "    \n",
    "def get_triplet(test=False):\n",
    "    \"\"\"Choose a triplet (anchor, positive, negative) of images\n",
    "    such that anchor and positive have the same label and\n",
    "    anchor and negative have different labels.\"\"\"\n",
    "    n = a = np.random.randint(10)\n",
    "    while n == a:\n",
    "        # keep searching randomly!\n",
    "        n = np.random.randint(10)\n",
    "    a, p = get_image(a, test), get_image(a, test)\n",
    "    n = get_image(n, test)\n",
    "    return a, p, n\n",
    "\n",
    "def generate_triplets(test=False):\n",
    "    \"\"\"Generate an un-ending stream (ie a generator) of triplets for\n",
    "    training or test.\"\"\"\n",
    "    while True:\n",
    "        list_a = []\n",
    "        list_p = []\n",
    "        list_n = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            a, p, n = get_triplet(test)\n",
    "            list_a.append(a)\n",
    "            list_p.append(p)\n",
    "            list_n.append(n)\n",
    "            \n",
    "        A = np.array(list_a, dtype='float32')\n",
    "        P = np.array(list_p, dtype='float32')\n",
    "        N = np.array(list_n, dtype='float32')\n",
    "        # a \"dummy\" label which will come in to our identity loss\n",
    "        # function below as y_true. We'll ignore it.\n",
    "        label = np.ones(batch_size)\n",
    "        yield [A, P, N], label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_loss(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "def triplet_loss(x, alpha = 0.2):\n",
    "    # Triplet Loss function.\n",
    "    anchor,positive,negative = x\n",
    "    # distance between the anchor and the positive\n",
    "    pos_dist = K.sum(K.square(anchor-positive),axis=1)\n",
    "    # distance between the anchor and the negative\n",
    "    neg_dist = K.sum(K.square(anchor-negative),axis=1)\n",
    "    # compute loss\n",
    "    basic_loss = pos_dist-neg_dist+alpha\n",
    "    loss = K.maximum(basic_loss,0.0)\n",
    "    return loss\n",
    "\n",
    "def embedding_model():\n",
    "  # Simple convolutional model \n",
    "  # used for the embedding model.\n",
    "  model = Sequential()\n",
    "  model.add(Convolution2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(28,28,1)))\n",
    "  model.add(Convolution2D(32, (3, 3), activation='relu'))\n",
    "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "  model.add(Dropout(0.25))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(128, activation='relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(10))\n",
    "  return model\n",
    "\n",
    "\n",
    "def complete_model(base_model):\n",
    "    # Create the complete model with three\n",
    "    # embedding models and minimize the loss \n",
    "    # between their output embeddings\n",
    "    input_1 = Input((imsize, imsize, 1))\n",
    "    input_2 = Input((imsize, imsize, 1))\n",
    "    input_3 = Input((imsize, imsize, 1))\n",
    "        \n",
    "    A = base_model(input_1)\n",
    "    P = base_model(input_2)\n",
    "    N = base_model(input_3)\n",
    "   \n",
    "    loss = Lambda(triplet_loss)([A, P, N]) \n",
    "    model = Model(inputs=[input_1, input_2, input_3], outputs=loss)\n",
    "    model.compile(loss=identity_loss, optimizer=Adam(LR))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define aspects of the model and create instances of both the \n",
    "# test and train batch generators and the complete model.\n",
    "\n",
    "imsize = 28\n",
    "batch_size = 100\n",
    "embedding_dim = 2 \n",
    "LR = 0.0001\n",
    "EPOCHS = 5\n",
    "alpha = 0.2 \n",
    "\n",
    "train_generator = generate_triplets()\n",
    "test_generator = generate_triplets(test=True)\n",
    "batch = next(train_generator)\n",
    "\n",
    "base_model = embedding_model()\n",
    "model = complete_model(base_model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model using triplet images provided by the train batch generator.\n",
    "# Save the trained weights.\n",
    "history = model.fit_generator(train_generator, \n",
    "                    validation_data=test_generator, \n",
    "                    epochs=20, \n",
    "                    verbose=2,steps_per_epoch=20, \n",
    "                    validation_steps=30)\n",
    "model.save_weights('model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Training and Validation Losses',size = 20)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the newly trained model compute the embeddings \n",
    "# for a number images\n",
    "\n",
    "\n",
    "sample_size = 5000\n",
    "\n",
    "X_train_trm = base_model.predict(X_train[:sample_size].reshape(-1,28,28,1))\n",
    "X_test_trm = base_model.predict(X_test[:sample_size].reshape(-1,28,28,1))\n",
    "\n",
    "# TSNE to use dimensionality reduction to visulaise the resultant embeddings\n",
    "tsne = TSNE()\n",
    "train_tsne_embeds = tsne.fit_transform(X_train_trm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def scatter(x, labels, subtitle=None):\n",
    "    # Create a scatter plot of all the \n",
    "    # the embeddings of the model.\n",
    "    # We choose a color palette with seaborn.\n",
    "    palette = np.array(sns.color_palette(\"hls\", 10))\n",
    "    # We create a scatter plot.\n",
    "    f = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    sc = ax.scatter(x[:,0], x[:,1], lw=0,alpha = 0.5, s=40,\n",
    "                    c=palette[labels.astype(np.int)] )\n",
    "    plt.xlim(-25, 25)\n",
    "    plt.ylim(-25, 25)\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "    \n",
    "    \n",
    "\n",
    "scatter(train_tsne_embeds, y_train[:sample_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Classifier that computes the class of a specific embedding. \n",
    "Classifier_input = Input((10,))\n",
    "Classifier_output = Dense(10, activation='softmax')(Classifier_input)\n",
    "Classifier_model = Model(Classifier_input, Classifier_output)\n",
    "\n",
    "# convert the target labels to onehot encoded vectors.\n",
    "Y_train_onehot = np_utils.to_categorical(y_train, 10)[:sample_size]\n",
    "Y_test_onehot = np_utils.to_categorical(y_test, 10)[:sample_size]\n",
    "\n",
    "Classifier_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "Classifier_model.fit(X_train_trm,Y_train_onehot, validation_data=(X_test_trm,Y_test_onehot),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import io\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(x):\n",
    "    # calculates the gini coeffiecent of \n",
    "    # an array. \n",
    "    mad = np.abs(np.subtract.outer(x, x)).mean()\n",
    "    rmad = mad/np.mean(x)\n",
    "    g = 0.5 * rmad\n",
    "    return g\n",
    "\n",
    "def DigitOrNumber(x):\n",
    "  # Creates an embedding for an image and then calculates the \n",
    "  # equality of the softmax prediction distribution if it is below a certain threshold\n",
    "  # then the image will be classified as a digit\n",
    "  temp = base_model.predict(x)\n",
    "  temp = Classifier_model.predict(temp)\n",
    "  if gini(temp) < 0.87:\n",
    "    print(np.argmax(temp))\n",
    "  else:\n",
    "    print('Input is not a Digit')\n",
    "    \n",
    "# a few examples\n",
    "x= np.load(io.BytesIO(uploaded['emnist_train_images_3 (1).npy'])) \n",
    "DigitOrNumber(x[0:1])\n",
    "DigitOrNumber(x[1:2])\n",
    "DigitOrNumber(x[2:3])\n",
    "DigitOrNumber(X_test[20:21])\n",
    "DigitOrNumber(X_test[500:501])\n",
    "DigitOrNumber(X_test[1007:1008])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "# load the image net VGG16\n",
    "model = VGG16(weights='imagenet', include_top=False, pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "# This will prompt for authorization.\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "image_path = [\"drive/My Drive/data/val/ben_afflek/\",\"drive/My Drive/data/val/elton_john/\",\"drive/My Drive/data/val/madonna/\",\"drive/My Drive/data/val/jerry_seinfeld/\",\"drive/My Drive/data/val/mindy_kaling/\"]\n",
    "newFolder = \"drive/My Drive/data/Train\"\n",
    "\n",
    "\n",
    "def save_faces(cascade, imgname, image_path):\n",
    "  # uses the casca Haar cascade to isolate the\n",
    "  # face from an image.\n",
    "  img = cv2.imread(os.path.join(image_path, imgname))\n",
    "  celebrity = image_path.split(\"/\")[-2]\n",
    "  for i, face in enumerate(cascade.detectMultiScale(img)):\n",
    "      x, y, w, h = face\n",
    "      sub_face = img[y:y + h, x:x + w]\n",
    "      resized_image = cv2.resize(sub_face, (224, 224))\n",
    "      name = celebrity + str(face[0]) +'.jpg'\n",
    "      #plt.imshow(resized_image)\n",
    "      #plt.show()\n",
    "      cv2.imwrite(os.path.join(newFolder,name), resized_image)\n",
    "  \n",
    "\n",
    "\n",
    "face_cascade = \"drive/My Drive/haarcascade_frontalface_default.xml\"\n",
    "cascade = cv2.CascadeClassifier(face_cascade)\n",
    "# Iterate through files\n",
    "for path in image_path:\n",
    "  for f in [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]:\n",
    "    save_faces(cascade, f,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "from keras.models import Model \n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras import applications\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "from IPython.core.display import Image\n",
    "\n",
    "# Vgg16 architecture.\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
    "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(2622, (1, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "model.load_weights('drive/My Drive/VGG_face_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the top layers to reveal a flatten dense layer\n",
    "# for embedding.\n",
    "vgg_face_descriptor = Model(inputs=model.layers[0].input\n",
    ", outputs=model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Names = []\n",
    "attributes = []\n",
    "path = \"drive/My Drive/data/Train/\"\n",
    "for f in [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]:\n",
    "  img = image.load_img(os.path.join(path, f), target_size=(224, 224))\n",
    "  # convert image to numpy array\n",
    "  x = image.img_to_array(img)\n",
    "  # the image is now in an array of shape (3, 224, 224) \n",
    "  # need to expand it to (1, 3, 224, 224) as it's expecting a list\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  x = preprocess_input(x)\n",
    "  # extract the features\n",
    "  Names.append(f)\n",
    "  attributes.append(vgg_face_descriptor.predict(x)[0])\n",
    "  \n",
    "x = np.asarray(attributes)\n",
    "y = np.asarray(Names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter(x, labels, subtitle=None):\n",
    "    # We choose a color palette with seaborn.\n",
    "    palette = np.array(sns.color_palette(\"hls\", 5))\n",
    "    # We create a scatter plot.\n",
    "    f = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    sc = ax.scatter(x[:,0], x[:,1], lw=0,alpha = 0.5, s=40)\n",
    "    plt.xlim(-25, 25)\n",
    "    plt.ylim(-25, 25)\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "\n",
    "tsne = TSNE()\n",
    "train_tsne_embeds = tsne.fit_transform(x)    \n",
    "newy = [''.join(i for i in stri if not i.isdigit()) for stri in y]\n",
    "labelss = [stri.rsplit( \".\", 1 )[ 0 ] for stri in newy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "scatterDF =  pd.DataFrame(\n",
    "    {'X': train_tsne_embeds[:,0],\n",
    "     'Y': train_tsne_embeds[:,1],\n",
    "     'Label': labelss\n",
    "    })\n",
    "\n",
    "customPalette = ['#630C3A', '#39C8C6', '#D3500C', '#FFB139',\"#FFF000\"]\n",
    "\n",
    "facet = sns.lmplot(data=scatterDF, x='X', y='Y', hue='Label', \n",
    "                   fit_reg=False, legend=False)\n",
    "\n",
    "#add a legend\n",
    "leg = facet.ax.legend(bbox_to_anchor=[1, 0.75],\n",
    "                         title=\"label\", fancybox=True)\n",
    "\n",
    "\n",
    "#change colors of labels\n",
    "for i, text in enumerate(leg.get_texts()):\n",
    "    plt.setp(text,color = customPalette[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "cluster = AgglomerativeClustering(n_clusters=5, affinity='euclidean', linkage='ward')  \n",
    "cluster.fit_predict(train_tsne_embeds) \n",
    "\n",
    "scatterDF =  pd.DataFrame(\n",
    "    {'X': train_tsne_embeds[:,0],\n",
    "     'Y': train_tsne_embeds[:,1],\n",
    "     'Label': cluster.labels_\n",
    "    })\n",
    "\n",
    "customPalette = ['#630C3A', '#39C8C6', '#D3500C', '#FFB139',\"#FFF000\"]\n",
    "facet = sns.lmplot(data=scatterDF, x='X', y='Y', hue='Label', \n",
    "                   fit_reg=False, legend=False)\n",
    "\n",
    "#add a legend\n",
    "leg = facet.ax.legend(bbox_to_anchor=[1, 0.75],\n",
    "                         title=\"label\", fancybox=True)\n",
    "#change colors of labels\n",
    "for i, text in enumerate(leg.get_texts()):\n",
    "    plt.setp(text,color = customPalette[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import BboxImage\n",
    "from matplotlib.transforms import Bbox, TransformedBbox\n",
    "\n",
    "path = \"drive/My Drive/data/Train/\"\n",
    "all_paths = []\n",
    "for f in [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]:\n",
    "  all_paths.append(os.path.join(path, f))\n",
    "  \n",
    "def NormalizeData(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "  \n",
    "  \n",
    "norm1 = NormalizeData(train_tsne_embeds[:,0])\n",
    "norm2 = NormalizeData(train_tsne_embeds[:,1])\n",
    "  \n",
    "fig = plt.figure(figsize=(15,15))\n",
    "ax = fig.add_subplot(111)\n",
    "for i in range(len(train_tsne_embeds)):\n",
    "  bb = Bbox.from_bounds(norm1[i], norm2[i], 0.05, 0.05)\n",
    "  bb2 = TransformedBbox(bb, ax.transData)\n",
    "  bbox_image = BboxImage(bb2, norm=None, origin=None, clip_on=False)\n",
    "  bbox_image.set_data(image.load_img(all_paths[i]))\n",
    "  ax.add_artist(bbox_image)\n",
    "\n",
    "\n",
    "ax.set_ylim(0,1.2)  \n",
    "ax.set_xlim(0,1.2) \n",
    "ax.set_facecolor((1.0, 1.0, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "knn = NearestNeighbors(n_neighbors=4)\n",
    "# Fit the model on the training data.\n",
    "knn.fit(x)\n",
    "# Make point predictions on the test set using the fit model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the three most similar images to a base image\n",
    "# using KNN nearest neighbours algorithm provided by Scikit Learn\n",
    "recomendations = knn.kneighbors(x[66].reshape(1,-1),return_distance=False)\n",
    "path = \"drive/My Drive/data/Train/\"\n",
    "for i in range(recomendations.shape[1]):\n",
    "  display(Image(filename=os.path.join(path, y[recomendations[0][i]])))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7df4d15e59cac213afef75c805c6c35b948ade230879836dc77c436b6318e246"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('intro-ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
